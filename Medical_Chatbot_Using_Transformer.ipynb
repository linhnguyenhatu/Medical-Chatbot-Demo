{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "VTLOyTcUPmvH",
    "outputId": "01e31727-3758-42de-a1e3-484f1ff3450f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import torchtext.vocab as tvc\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eECAaLN4QYE1"
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iD-LkPwgQc2h"
   },
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "\n",
    "df = pd.read_csv('Dataset/train_medical_chatbot.csv', engine='python', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYHjRhfNUFTv"
   },
   "outputs": [],
   "source": [
    "#Preprocess dataset\n",
    "wordnet = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "def get_rid_of_q(text):\n",
    "  if text is None:\n",
    "      return \"\"  \n",
    "  return text.replace(\"Q. \", \"\")\n",
    "\n",
    "def clean_text(text):\n",
    "  text = get_rid_of_q(text)\n",
    "  text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "  text = text.lower()\n",
    "  text = text.split()\n",
    "  text = [wordnet.lemmatize(word) for word in text][:1000]\n",
    "  return text\n",
    "\n",
    "def add_eos(text):\n",
    "  text = text + [\"<eos>\"]\n",
    "  return text\n",
    "df[\"Description\"] = df[\"Description\"].apply(clean_text)\n",
    "df[\"Patient\"] = df[\"Patient\"].apply(clean_text)\n",
    "df[\"Patient\"] = df[\"Patient\"].apply(add_eos)\n",
    "df[\"Doctor\"] = df[\"Doctor\"].apply(clean_text)\n",
    "df[\"Doctor\"] = df[\"Doctor\"].apply(add_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdGvZwbAab5-"
   },
   "outputs": [],
   "source": [
    "#Build/Load vocabulary\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "eos_token = \"<eos>\"\n",
    "special_tokens = [unk_token, pad_token, eos_token]\n",
    "min_freq = 2\n",
    "whole_text = df[\"Description\"].tolist() + df[\"Patient\"].tolist() + df[\"Doctor\"].tolist()\n",
    "if torch.load('Load_Vocabulary/text_vocabulary.pt') == None:\n",
    "    text_vocabulary = tvc.build_vocab_from_iterator(whole_text, min_freq=min_freq, specials=special_tokens)\n",
    "else:\n",
    "    text_vocabulary = torch.load('Load_Vocabulary/text_vocabulary.pt')\n",
    "text_vocabulary.set_default_index(text_vocabulary[unk_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oaQ33DAb80R"
   },
   "outputs": [],
   "source": [
    "#Combine description and patient prompt\n",
    "\n",
    "df[\"Patient\"] = df[\"Description\"] + df[\"Patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaLoMSgDbP3U"
   },
   "outputs": [],
   "source": [
    "#Numberize the tokens\n",
    "\n",
    "def token_to_index(tokens):\n",
    "  return text_vocabulary.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "R8V8PRTbS2PX"
   },
   "outputs": [],
   "source": [
    "#Numberizing and padding the dataset\n",
    "\n",
    "df[\"Patient\"] = df[\"Patient\"].apply(token_to_index)\n",
    "df[\"Doctor\"] = df[\"Doctor\"].apply(token_to_index)\n",
    "input = [torch.tensor(x) for x in df[\"Patient\"]]\n",
    "output = [torch.tensor(y) for y in df[\"Doctor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the training input and output\n",
    "input = input[7300:]\n",
    "output = output[7300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtLgN6Stip-I"
   },
   "outputs": [],
   "source": [
    "#Build the model\n",
    "class pos_encoder(nn.Module):\n",
    "  def __init__(self, embedding_size, max_len):\n",
    "    super().__init__()\n",
    "    self.pos_mat = torch.zeros(max_len, embedding_size)\n",
    "\n",
    "    position = torch.arange(0, max_len, step = 1).float().unsqueeze(1)\n",
    "    embedding_value = torch.arange(0, embedding_size, step = 2).float()\n",
    "    div_term = 1/torch.tensor(100000.0)**(embedding_value/embedding_size)\n",
    "    self.pos_mat[:, 0::2] = torch.sin(position*div_term)\n",
    "    self.pos_mat[:, 1::2] = torch.cos(position*div_term)\n",
    "    print(self.pos_mat)\n",
    "\n",
    "  def forward(self, x):\n",
    "    print(self.pos_mat[:x.size(0), :].shape)\n",
    "    print(x.shape)\n",
    "    return x + self.pos_mat[:x.size(0), :]\n",
    "\n",
    "class attention(nn.Module):\n",
    "  def __init__(self, embedding_size):\n",
    "    super().__init__()\n",
    "    self.w_query = nn.Linear(embedding_size, embedding_size, bias = False)\n",
    "    self.w_key = nn.Linear(embedding_size, embedding_size, bias = False)\n",
    "    self.w_value = nn.Linear(embedding_size, embedding_size, bias = False)\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "    query = self.w_query(x)\n",
    "    key = self.w_key(x)\n",
    "    value = self.w_value(x)\n",
    "    similarity = torch.matmul(query, key.transpose(0, 1))\n",
    "\n",
    "    if mask != None:\n",
    "      similarity = similarity.masked_fill(mask = mask, value = -1e9)\n",
    "\n",
    "    attention_percentage = torch.nn.functional.softmax(similarity, dim = 0)\n",
    "    attention_score = torch.matmul(attention_percentage, value)\n",
    "    return attention_score\n",
    "\n",
    "class residual_connection(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x, position_value):\n",
    "    return x + position_value\n",
    "\n",
    "  \n",
    "class Transformer(nn.Module):\n",
    "  def __init__(self, input_vocab, embedding_size, max_len = 1000):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(input_vocab, embedding_size)\n",
    "    self.pos_encoder = pos_encoder(embedding_size, max_len)\n",
    "    self.attention = attention(embedding_size)\n",
    "    self.residual_connection = residual_connection()\n",
    "    self.embedding_size = embedding_size\n",
    "    self.max_len = max_len\n",
    "    self.fc = nn.Linear(embedding_size, input_vocab)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.embedding(x)\n",
    "    pos = self.pos_encoder(out)\n",
    "    mask = torch.tril(torch.ones(x.size(0), x.size(0)))\n",
    "    mask = mask == 0\n",
    "    out = self.attention(pos, mask)\n",
    "    out = self.residual_connection(out, pos)\n",
    "    out = self.fc(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model, loss, and optimizer functions\n",
    "\n",
    "model = Transformer(len(text_vocabulary), 100)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model checkpoint\n",
    "\n",
    "check_point = torch.load('Model_Checkpoint/check-point-after-adjusted-optimizer-and-restart-model.pt')\n",
    "model.load_state_dict(check_point['model_state_dict'])\n",
    "optimizer.load_state_dict(check_point['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "def train():\n",
    "    num_epoch = 1\n",
    "    for epoch in range(num_epoch):\n",
    "        train_one_epoch()\n",
    "\n",
    "def train_one_epoch():\n",
    "    count_data = 0\n",
    "    count_word = 0\n",
    "    l_total = 0\n",
    "    for i in range(len(input)):\n",
    "        input_tokens = input[i]\n",
    "        prediction = model(input_tokens)\n",
    "        result = prediction[-1, :]\n",
    "        result_id = torch.tensor([torch.argmax(result)])\n",
    "        index = 0\n",
    "        output_list = result_id\n",
    "        for j in range(len(output[i])):\n",
    "            if result_id.item() == text_vocabulary[eos_token]:\n",
    "                break\n",
    "            expect_output = torch.cat([input_tokens[1:], torch.tensor([output[i][0]])], dim = 0)\n",
    "            print(prediction.shape)\n",
    "            print(expect_output.shape)\n",
    "            l = loss(prediction, expect_output)\n",
    "            l_total += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            count_word += 1\n",
    "            input_tokens = torch.concat([input_tokens, torch.tensor([output[i][j]])], dim = 0)\n",
    "            prediction = model(input_tokens)\n",
    "            result = prediction[-1, :]\n",
    "            result_id = torch.tensor([torch.argmax(result)])\n",
    "            output_list = torch.cat([output_list, result_id], dim = 0)\n",
    "            index += 1\n",
    "        count_data += 1\n",
    "        print(f\"Loss of word {count_data} is: {l_total/count_word} \")\n",
    "        if count_data % 10 == 0:\n",
    "            torch.save({\n",
    "            'num_data': count_data,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': l_total/count_word,\n",
    "            }, \"check-point-after-adjusted-optimizer-and-restart-model.pt\")\n",
    "                  \n",
    "train() #Start training the model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeAJxcgjPrJb"
   },
   "outputs": [],
   "source": [
    "#Model testing with inputs from keyboard\n",
    "\n",
    "input_test = \"What is pregnancy\"\n",
    "input_test = get_rid_of_q(input_test)\n",
    "input_test = clean_text(input_test)\n",
    "input_test = add_eos(input_test)\n",
    "input_test = token_to_index(input_test)\n",
    "input_test = torch.tensor(input_test)\n",
    "prediction = model(input_test)\n",
    "result = prediction[-1, :]\n",
    "result_id = torch.tensor([torch.argmax(result)])\n",
    "output_list = result_id\n",
    "for i in range(len(input_test), 1000):\n",
    "    if result_id.item() == text_vocabulary[eos_token]:\n",
    "            break\n",
    "    input_test = torch.concat([input_test, result_id], dim = 0)\n",
    "    prediction = model(input_test)\n",
    "    result = prediction[-1, :]\n",
    "    result_id = torch.tensor([torch.argmax(result)])\n",
    "    output_list = torch.cat([output_list, result_id], dim = 0)\n",
    "final = text_vocabulary.lookup_tokens(output_list.tolist())\n",
    "print(' '.join(final))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
