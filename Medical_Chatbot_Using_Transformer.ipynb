{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9nkRI6KcIzr",
    "outputId": "efaa5b69-7980-4dbe-869f-f2a7186512ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\linhn\\anaconda3\\envs\\pytorch\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\linhn\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\linhn\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\linhn\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\linhn\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\linhn\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "VTLOyTcUPmvH",
    "outputId": "01e31727-3758-42de-a1e3-484f1ff3450f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import torchtext.vocab as tvc\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "eECAaLN4QYE1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\linhn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\linhn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iD-LkPwgQc2h"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Import Dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset/train_medical_chatbot.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Import Dataset\n",
    "\n",
    "df = pd.read_csv('Dataset/train_medical_chatbot.csv', engine='python', on_bad_lines='skip')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYHjRhfNUFTv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[what, doe, abutment, of, the, nerve, root, mean]</td>\n",
       "      <td>[hi, doctor, i, am, just, wondering, what, is,...</td>\n",
       "      <td>[hi, i, have, gone, through, your, query, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[what, should, i, do, to, reduce, my, weight, ...</td>\n",
       "      <td>[hi, doctor, i, am, a, year, old, female, who,...</td>\n",
       "      <td>[hi, you, have, really, done, well, with, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, have, started, to, get, lot, of, acne, on,...</td>\n",
       "      <td>[hi, doctor, i, used, to, have, clear, skin, b...</td>\n",
       "      <td>[hi, there, acne, ha, multifactorial, etiology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[why, do, i, have, uncomfortable, feeling, bet...</td>\n",
       "      <td>[hello, doctor, i, am, having, an, uncomfortab...</td>\n",
       "      <td>[hello, the, popping, and, discomfort, what, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[my, symptom, after, intercourse, threatns, me...</td>\n",
       "      <td>[hello, doctor, before, two, year, had, sex, w...</td>\n",
       "      <td>[hello, the, hiv, test, us, a, finger, prick, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45548</th>\n",
       "      <td>[feeling, of, fogginess, brain, doe, not, seem...</td>\n",
       "      <td>[hello, doctor, i, from, a, couple, of, day, i...</td>\n",
       "      <td>[hi, thank, you, for, posting, your, query, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45549</th>\n",
       "      <td>[ateriovenous, malformation, inter, cerebral, ...</td>\n",
       "      <td>[can, an, avm, leak, while, apersn, sleep, eno...</td>\n",
       "      <td>[hi, thank, you, for, posting, your, query, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45550</th>\n",
       "      <td>[what, doe, this, mri, report, of, brain, show...</td>\n",
       "      <td>[hi, doctor, i, had, an, mri, day, ago, it, sa...</td>\n",
       "      <td>[hellothanks, for, writing, to, hcmslight, amo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45551</th>\n",
       "      <td>[tiredness, dizziness, tingling, of, arm, ches...</td>\n",
       "      <td>[hi, i, m, year, old, a, female, and, weight, ...</td>\n",
       "      <td>[hi, thank, you, for, posting, your, query, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45552</th>\n",
       "      <td>[suffering, from, brain, problem, taking, oxet...</td>\n",
       "      <td>[hello, sir, i, am, pooja, age, i, am, surfing...</td>\n",
       "      <td>[hi, m, pooja, thank, you, for, posting, your,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45553 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description  \\\n",
       "0      [what, doe, abutment, of, the, nerve, root, mean]   \n",
       "1      [what, should, i, do, to, reduce, my, weight, ...   \n",
       "2      [i, have, started, to, get, lot, of, acne, on,...   \n",
       "3      [why, do, i, have, uncomfortable, feeling, bet...   \n",
       "4      [my, symptom, after, intercourse, threatns, me...   \n",
       "...                                                  ...   \n",
       "45548  [feeling, of, fogginess, brain, doe, not, seem...   \n",
       "45549  [ateriovenous, malformation, inter, cerebral, ...   \n",
       "45550  [what, doe, this, mri, report, of, brain, show...   \n",
       "45551  [tiredness, dizziness, tingling, of, arm, ches...   \n",
       "45552  [suffering, from, brain, problem, taking, oxet...   \n",
       "\n",
       "                                                 Patient  \\\n",
       "0      [hi, doctor, i, am, just, wondering, what, is,...   \n",
       "1      [hi, doctor, i, am, a, year, old, female, who,...   \n",
       "2      [hi, doctor, i, used, to, have, clear, skin, b...   \n",
       "3      [hello, doctor, i, am, having, an, uncomfortab...   \n",
       "4      [hello, doctor, before, two, year, had, sex, w...   \n",
       "...                                                  ...   \n",
       "45548  [hello, doctor, i, from, a, couple, of, day, i...   \n",
       "45549  [can, an, avm, leak, while, apersn, sleep, eno...   \n",
       "45550  [hi, doctor, i, had, an, mri, day, ago, it, sa...   \n",
       "45551  [hi, i, m, year, old, a, female, and, weight, ...   \n",
       "45552  [hello, sir, i, am, pooja, age, i, am, surfing...   \n",
       "\n",
       "                                                  Doctor  \n",
       "0      [hi, i, have, gone, through, your, query, with...  \n",
       "1      [hi, you, have, really, done, well, with, the,...  \n",
       "2      [hi, there, acne, ha, multifactorial, etiology...  \n",
       "3      [hello, the, popping, and, discomfort, what, y...  \n",
       "4      [hello, the, hiv, test, us, a, finger, prick, ...  \n",
       "...                                                  ...  \n",
       "45548  [hi, thank, you, for, posting, your, query, i,...  \n",
       "45549  [hi, thank, you, for, posting, your, query, i,...  \n",
       "45550  [hellothanks, for, writing, to, hcmslight, amo...  \n",
       "45551  [hi, thank, you, for, posting, your, query, i,...  \n",
       "45552  [hi, m, pooja, thank, you, for, posting, your,...  \n",
       "\n",
       "[45553 rows x 3 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess dataset\n",
    "wordnet = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "def get_rid_of_q(text):\n",
    "  if text is None:\n",
    "      return \"\"  \n",
    "  return text.replace(\"Q. \", \"\")\n",
    "\n",
    "def clean_text(text):\n",
    "  text = get_rid_of_q(text)\n",
    "  text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "  text = text.lower()\n",
    "  text = text.split()\n",
    "  text = [wordnet.lemmatize(word) for word in text][:1000]\n",
    "  return text\n",
    "\n",
    "def add_eos(text):\n",
    "  text = text + [\"<eos>\"]\n",
    "  return text\n",
    "df[\"Description\"] = df[\"Description\"].apply(clean_text)\n",
    "df[\"Patient\"] = df[\"Patient\"].apply(clean_text)\n",
    "df[\"Patient\"] = df[\"Patient\"].apply(add_eos)\n",
    "df[\"Doctor\"] = df[\"Doctor\"].apply(clean_text)\n",
    "df[\"Doctor\"] = df[\"Doctor\"].apply(add_eos)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdGvZwbAab5-"
   },
   "outputs": [],
   "source": [
    "#Build/Load vocabulary\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "eos_token = \"<eos>\"\n",
    "special_tokens = [unk_token, pad_token, eos_token]\n",
    "min_freq = 2\n",
    "whole_text = df[\"Description\"].tolist() + df[\"Patient\"].tolist() + df[\"Doctor\"].tolist()\n",
    "if torch.load('Load_Vocabulary/text_vocabulary.pt') == None:\n",
    "    text_vocabulary = tvc.build_vocab_from_iterator(whole_text, min_freq=min_freq, specials=special_tokens)\n",
    "else:\n",
    "    text_vocabulary = torch.load('Load_Vocabulary/text_vocabulary.pt')\n",
    "text_vocabulary.set_default_index(text_vocabulary[unk_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOA23D8HbGfS"
   },
   "outputs": [],
   "source": [
    "torch.save(text_vocabulary, 'Load_Vocabulary/text_vocabulary.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oaQ33DAb80R"
   },
   "outputs": [],
   "source": [
    "#Combine description and patient prompt\n",
    "\n",
    "df[\"Patient\"] = df[\"Description\"] + df[\"Patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaLoMSgDbP3U"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Numberize the tokens\n",
    "def token_to_index(tokens):\n",
    "  return text_vocabulary.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "R8V8PRTbS2PX"
   },
   "outputs": [],
   "source": [
    "#Numberizing and padding the dataset\n",
    "\n",
    "df[\"Patient\"] = df[\"Patient\"].apply(token_to_index)\n",
    "df[\"Doctor\"] = df[\"Doctor\"].apply(token_to_index)\n",
    "input = [torch.tensor(x) for x in df[\"Patient\"]]\n",
    "output = [torch.tensor(y) for y in df[\"Doctor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the training input and output\n",
    "input = input[7300:]\n",
    "output = output[7300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtLgN6Stip-I"
   },
   "outputs": [],
   "source": [
    "#Build the model\n",
    "class pos_encoder(nn.Module):\n",
    "  def __init__(self, embedding_size, max_len):\n",
    "    super().__init__()\n",
    "    self.pos_mat = torch.zeros(max_len, embedding_size)\n",
    "\n",
    "    position = torch.arange(0, max_len, step = 1).float().unsqueeze(1)\n",
    "    embedding_value = torch.arange(0, embedding_size, step = 2).float()\n",
    "    div_term = 1/torch.tensor(100000.0)**(embedding_value/embedding_size)\n",
    "    self.pos_mat[:, 0::2] = torch.sin(position*div_term)\n",
    "    self.pos_mat[:, 1::2] = torch.cos(position*div_term)\n",
    "    print(self.pos_mat)\n",
    "\n",
    "  def forward(self, x):\n",
    "    print(self.pos_mat[:x.size(0), :].shape)\n",
    "    print(x.shape)\n",
    "    return x + self.pos_mat[:x.size(0), :]\n",
    "\n",
    "class attention(nn.Module):\n",
    "  def __init__(self, embedding_size):\n",
    "    super().__init__()\n",
    "    self.w_query = nn.Linear(embedding_size, embedding_size, bias = False)\n",
    "    self.w_key = nn.Linear(embedding_size, embedding_size, bias = False)\n",
    "    self.w_value = nn.Linear(embedding_size, embedding_size, bias = False)\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "    query = self.w_query(x)\n",
    "    key = self.w_key(x)\n",
    "    value = self.w_value(x)\n",
    "    similarity = torch.matmul(query, key.transpose(0, 1))\n",
    "\n",
    "    if mask != None:\n",
    "      similarity = similarity.masked_fill(mask = mask, value = -1e9)\n",
    "\n",
    "    attention_percentage = torch.nn.functional.softmax(similarity, dim = 0)\n",
    "    attention_score = torch.matmul(attention_percentage, value)\n",
    "    return attention_score\n",
    "\n",
    "class residual_connection(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x, position_value):\n",
    "    return x + position_value\n",
    "\n",
    "  \n",
    "class Transformer(nn.Module):\n",
    "  def __init__(self, input_vocab, embedding_size, max_len = 1000):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(input_vocab, embedding_size)\n",
    "    self.pos_encoder = pos_encoder(embedding_size, max_len)\n",
    "    self.attention = attention(embedding_size)\n",
    "    self.residual_connection = residual_connection()\n",
    "    self.embedding_size = embedding_size\n",
    "    self.max_len = max_len\n",
    "    self.fc = nn.Linear(embedding_size, input_vocab)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.embedding(x)\n",
    "    pos = self.pos_encoder(out)\n",
    "    mask = torch.tril(torch.ones(x.size(0), x.size(0)))\n",
    "    mask = mask == 0\n",
    "    out = self.attention(pos, mask)\n",
    "    out = self.residual_connection(out, pos)\n",
    "    out = self.fc(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  7.1339e-01,  ...,  1.0000e+00,\n",
      "          1.2589e-05,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.9984e-01,  ...,  1.0000e+00,\n",
      "          2.5179e-05,  1.0000e+00],\n",
      "        ...,\n",
      "        [-8.9797e-01, -4.4006e-01,  2.6085e-01,  ...,  9.9988e-01,\n",
      "          1.2551e-02,  9.9992e-01],\n",
      "        [-8.5547e-01,  5.1785e-01,  8.7148e-01,  ...,  9.9987e-01,\n",
      "          1.2564e-02,  9.9992e-01],\n",
      "        [-2.6461e-02,  9.9965e-01,  9.6058e-01,  ...,  9.9987e-01,\n",
      "          1.2576e-02,  9.9992e-01]])\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model, loss, and optimizer functions\n",
    "\n",
    "model = Transformer(len(text_vocabulary), 100)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model checkpoint\n",
    "\n",
    "check_point = torch.load('Model_Checkpoint/check-point-after-adjusted-optimizer-and-restart-model.pt')\n",
    "model.load_state_dict(check_point['model_state_dict'])\n",
    "optimizer.load_state_dict(check_point['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "\n",
    "def train():\n",
    "    num_epoch = 1\n",
    "    for epoch in range(num_epoch):\n",
    "        train_one_epoch()\n",
    "\n",
    "def train_one_epoch():\n",
    "    count_data = 0\n",
    "    count_word = 0\n",
    "    l_total = 0\n",
    "    for i in range(len(input)):\n",
    "        input_tokens = input[i]\n",
    "        prediction = model(input_tokens)\n",
    "        result = prediction[-1, :]\n",
    "        result_id = torch.tensor([torch.argmax(result)])\n",
    "        index = 0\n",
    "        output_list = result_id\n",
    "        for j in range(len(output[i])):\n",
    "            if result_id.item() == text_vocabulary[eos_token]:\n",
    "                break\n",
    "            expect_output = torch.cat([input_tokens[1:], torch.tensor([output[i][0]])], dim = 0)\n",
    "            print(prediction.shape)\n",
    "            print(expect_output.shape)\n",
    "            l = loss(prediction, expect_output)\n",
    "            l_total += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            count_word += 1\n",
    "            input_tokens = torch.concat([input_tokens, torch.tensor([output[i][j]])], dim = 0)\n",
    "            prediction = model(input_tokens)\n",
    "            result = prediction[-1, :]\n",
    "            result_id = torch.tensor([torch.argmax(result)])\n",
    "            output_list = torch.cat([output_list, result_id], dim = 0)\n",
    "            index += 1\n",
    "        count_data += 1\n",
    "        print(f\"Loss of word {count_data} is: {l_total/count_word} \")\n",
    "        if count_data % 10 == 0:\n",
    "            torch.save({\n",
    "            'num_data': count_data,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': l_total/count_word,\n",
    "            }, \"check-point-after-adjusted-optimizer-and-restart-model.pt\")\n",
    "            \n",
    "        \n",
    "train() #Start training the model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeAJxcgjPrJb"
   },
   "outputs": [],
   "source": [
    "input_test = \"What is pregnancy\"\n",
    "input_test = get_rid_of_q(input_test)\n",
    "input_test = clean_text(input_test)\n",
    "input_test = add_eos(input_test)\n",
    "input_test = token_to_index(input_test)\n",
    "print(input_test)\n",
    "input_test = torch.tensor(input_test)\n",
    "prediction = model(input_test)\n",
    "result = prediction[-1, :]\n",
    "result_id = torch.tensor([torch.argmax(result)])\n",
    "output_list = result_id\n",
    "for i in range(len(input_test), 1000):\n",
    "    if result_id.item() == text_vocabulary[eos_token]:\n",
    "            break\n",
    "    input_test = torch.concat([input_test, result_id], dim = 0)\n",
    "    prediction = model(input_test)\n",
    "    result = prediction[-1, :]\n",
    "    result_id = torch.tensor([torch.argmax(result)])\n",
    "    output_list = torch.cat([output_list, result_id], dim = 0)\n",
    "    \n",
    "print(type(output_list))\n",
    "final = text_vocabulary.lookup_tokens(output_list.tolist())\n",
    "print(' '.join(final))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
